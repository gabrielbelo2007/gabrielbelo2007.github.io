---
layout: post
title: "Aprendizado Supervisionado"
subtitle: Classificação e Regressão
date: 2025-09-28
author: Gabriel A. Belo
categories: [Computação]
tags: [IA | Machine Learning]
---

No último post sobre IA, foi apresentado um algoritmo de **Machine Learning** (ML), o **Teorema de Bayes**. Entretanto, algoritmos é apenas uma das aplicações práticas do ML.

Por isso, neste post vamos dar alguns passos para trás, para construir uma base sólida, e entender o que exatamente é o **aprendizado de máquina** e explorar um de seus paradigmas fundamentais, o **aprendizado supervisionado**.

### Sumário

- [O que é *Machine Learning*?](#o-que-é-machine-learning)
- [Aprendizagem Supervisionada](#aprendizagem-supervisionada)
- [Classificação](#classificação)
- [Regressão](#regressão)
- [*Overfitting* e *Underfitting*](#overfitting-e-underfitting)

### O que é *Machine Learning*?

A aprendizagem de máquina é um enorme campo dentro da **Inteligência Artificial**, que se dedica a construir métodos que permitam que as máquinas "aprendam" a partir de grandes bancos de dados.

Assim, essas máquinas tornam-se capazes de tomar decisões ou fazer previsões, por meio de padrões estruturados pela análise desses dados.

Em síntese, entregamos dados e escolhemos um método, para que a máquina os manipule e forneça uma resposta útil, sem que os desenvolvedores precisem pensar em todas as variáveis possíveis e construir um algoritmo bem restrito sobre como a máquina deve agir.

Portanto, se o objetivo é fazer a máquina aprender a partir de dados, como nós humanos, existem variados "métodos de estudo" *(paradigmas)* que definem nosso "aprendizado" *(aplicação)*, as máquinas não são diferentes.

No ML, existem três paradigmas principais: **Supervisionado**, **Não Supervisionado** e **Por Reforço**. Neste post, vamos focar no *Supervised Learning (SL)*, que é o mais comum para aplicações no dia a dia.

### Aprendizagem Supervisionada

Ainda fazendo uma conexão com a programação tradicional, imagine a seguinte situação:

- Eu quero fazer uma criança aprender a diferença entre gato e cachorro, para isso eu tenho duas opções:

    - Entregar um "manual" contendo todas as regras para distinguir um gato de um cachorro, diferenças na pata, orelhas, boca...
    - Mostrar diversos exemplos de gatos e cachorros e explicitar qual é qual.

Logicamente, a segunda opção parece melhor, até porque nós que já sabemos diferenciar um gato de um cachorro, talvez nem saibamos exatamente tudo que analisamos para fazer essa distinção.

Isso se tornou algo trivial em algum momento, a partir de uma repetida visualização de ambas as espécies.

> Esse paradigma é ideal para quando sabemos a resposta certa, mas não conseguimos formular uma regra que retorne essa resposta.

Como vimos, para problemas onde a quantidade de variáveis a serem analisadas é infinda, utilizamos o ML. 

Nesse caso, com o **aprendizado supervisionado**, fornecemos uma grande quantidade de dados rotulados (isso é um gato ou isso é um cachorro), que chamamos de **supervisão**.

Essa supervisão é importante, pois sabendo a resposta, a máquina pode avaliar sua previsão, aprendendo as características que definem um cachorro e um gato, e adequando seu modelo.

Ou seja, o algoritmo "aprende" a construir uma função (modelo de ML) onde uma nova foto gera uma previsão do rótulo, que é comparado com o rótulo real da imagem.

Em caso de erro (medido pela *loss function*), os parâmetros da função são ajustados e tenta-se novamente, até que o erro seja minimizado.

> Esses termos mais técnicos, como **Função de Perda** (*Loss Function*) ou minimização de erro, são a forma como a máquina quantifica o seu desempenho.

### Classificação

Existem dois tipos de problemas principais para os quais o **Aprendizado Supervisionado** é aplicado: **Classificação** (como o exemplo do gato/cachorro) e a **Regressão**.

Como já vimos um exemplo de classificação no tópico anterior, vamos entender como exatamente definimos esse tipo de problema.

A **Classificação** é usada para prever uma **categoria** ou **classe**, sendo assim, ao invés de estimativas numéricas, o objetivo é responder à pergunta: **"A qual grupo esse novo dado pertence?"**

No exemplo anterior, tínhamos duas categorias (gato ou cachorro) e nosso modelo, ao receber uma nova imagem, precisava decidir a qual desses grupos a imagem pertencia. Ou seja, o trabalho do **algoritmo de classificação** é construir uma função que consiga separar as categorias de forma eficiente.

Os dois formatos principais são a **classificação binária**, com apenas duas categorias possíveis (gato ou cachorro), ou a **classificação multiclasse**, quando há mais de duas categorias possíveis.

> A supervisão é essencial para que o algoritmo entenda como sua função deve separar os dados dentro das categorias, permitindo seu ajuste.

### Regressão

Com a Classificação, respondíamos à pergunta "Qual é o grupo?", com a **Regressão** podemos responder à pergunta **"Qual é o valor?"** ou **"Quanto custa?"**, ou seja, fazemos previsões de valores numéricos.

Pense na situação em que queremos prever o preço de uma casa (o valor é contínuo), o **algoritmo de regressão** recebe como entrada diversas características referentes a essa casa, como tamanho, número de quartos, distância de locais movimentados...

Analisando diversas outras casas com características similares e seus valores de venda, o algoritmo cria um modelo que gera uma previsão do valor de venda da casa com os dados recebidos e, como fundamental desse paradigma, ele compara a sua previsão com o valor real de venda (rótulo) e ajusta seus parâmetros a fim de minimizar seus erros.

Nesse caso, diferentemente da Classificação, em que o erro está em separar em uma classe errada, o erro da **Regressão** está em gerar um valor numérico de saída muito distante do valor real.

> A função de perda da **Regressão** retorna uma distância numérica real entre o valor previsto e o valor real, enquanto a função de perda da **Classificação** retorna um desvio probabilístico, mas ambas possuem o mesmo propósito de estimar a qualidade da resposta.

### *Overfitting* e *Underfitting*

Com isso, abordamos os principais problemas relacionados a um dos três paradigmas fundamentais do **Aprendizado de Máquina**.

Percebemos que a construção das funções envolve a busca constante pela minimização de erros, isso é o que move o aprendizado do modelo.

No entanto, se o modelo for ajustado em excesso ou de forma insuficiente, ele não será útil no mundo real. Isso nos leva a dois problemas cruciais na construção de modelos de *Machine Learning*: **Overfitting** e **Underfitting**.

No *Overfitting*, temos o "aluno que decora a apostila": o modelo, após um treinamento exaustivo com o mesmo conjunto de dados, torna-se muito complexo e começa a decorar os desvios de erro e os casos de exceção.

Assim, para dados desse conjunto, o modelo acerta quase 100%, porém, para dados nunca antes vistos, essa taxa de acerto despenca, pois a sua função não é realmente aplicável a qualquer contexto.

Já no *Underfitting*, a situação é contrária: "o aluno que não estudou o suficiente". O modelo foi treinado com poucos dados e não conseguiu captar nem padrões básicos desses dados, ou seja, ele não consegue uma taxa de acerto para os dados do conjunto de treinamento, nem para novos dados.

No fim, a meta ao construir esses modelos é encontrar um equilíbrio nesse treinamento, que permita uma constância alta para dados que pertencem ao conjunto de treinamento e para novos dados, mesmo que isso signifique não atingir 100% de acerto, mas chegar bem próximo disso.